<<BaseOptimizer>> <<10:149-162>> <<type>> <<CLASS>> <<ANCHOR>>
<<__init__>> <<29:733-741>> <<function>> <<CONSTRUCTOR>> <<ANCHOR>>
<<update_params>> <<34:953-966>> <<function>> <<METHOD>> <<ANCHOR>>
<<iteration_ends>> <<47:1412-1426>> <<function>> <<METHOD>> <<ANCHOR>>
<<trigger_stopping>> <<53:1592-1608>> <<function>> <<METHOD>> <<ANCHOR>>
<<SGDOptimizer>> <<74:2079-2091>> <<type>> <<CLASS>> <<ANCHOR>>
<<__init__>> <<118:3812-3820>> <<function>> <<CONSTRUCTOR>> <<ANCHOR>>
<<iteration_ends>> <<128:4239-4253>> <<function>> <<METHOD>> <<ANCHOR>>
<<trigger_stopping>> <<142:4771-4787>> <<function>> <<METHOD>> <<ANCHOR>>
<<_get_updates>> <<159:5378-5390>> <<function>> <<METHOD>> <<ANCHOR>>
<<AdamOptimizer>> <<184:6252-6265>> <<type>> <<CLASS>> <<ANCHOR>>
<<__init__>> <<231:7626-7634>> <<function>> <<CONSTRUCTOR>> <<ANCHOR>>
<<_get_updates>> <<242:8056-8068>> <<function>> <<METHOD>> <<ANCHOR>>
<<self>> <<118:3821-3825>> <<SGDOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<params>> <<118:3827-3833>> <<list>> <<PARAMETER>> <<ANCHOR>>
<<learning_rate_init>> <<118:3835-3853>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<lr_schedule>> <<118:3859-3870>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<momentum>> <<119:3901-3909>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<nesterov>> <<119:3915-3923>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<power_t>> <<119:3930-3937>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<lr_schedule>> <<122:4032-4043>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<momentum>> <<123:4072-4080>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<nesterov>> <<124:4106-4114>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<power_t>> <<125:4140-4147>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<param>> <<126:4211-4216>> <<?>> <<SCOPE>> <<ANCHOR>>
<<velocities>> <<126:4172-4182>> <<list>> <<ATTRIBUTE>> <<ANCHOR>>
<<self>> <<231:7635-7639>> <<AdamOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<params>> <<231:7641-7647>> <<list>> <<PARAMETER>> <<ANCHOR>>
<<learning_rate_init>> <<231:7649-7667>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<beta_1>> <<231:7675-7681>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<beta_2>> <<232:7705-7711>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<epsilon>> <<232:7719-7726>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<beta_1>> <<235:7823-7829>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<beta_2>> <<236:7853-7859>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<epsilon>> <<237:7883-7890>> <<?>> <<ATTRIBUTE>> <<ANCHOR>>
<<t>> <<238:7915-7916>> <<int>> <<ATTRIBUTE>> <<ANCHOR>>
<<param>> <<239:7966-7971>> <<?>> <<SCOPE>> <<ANCHOR>>
<<ms>> <<239:7935-7937>> <<list>> <<ATTRIBUTE>> <<ANCHOR>>
<<param>> <<240:8028-8033>> <<?>> <<SCOPE>> <<ANCHOR>>
<<vs>> <<240:7997-7999>> <<list>> <<ATTRIBUTE>> <<ANCHOR>>
<<self>> <<34:967-971>> <<AdamOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<grads>> <<34:973-978>> <<list>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<242:8069-8073>> <<AdamOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<grads>> <<242:8075-8080>> <<list>> <<PARAMETER>> <<ANCHOR>>
<<t>> <<256:8547-8548>> <<int>> <<ATTRIBUTE>> <<ANCHOR>>
<<ms>> <<257:8568-8570>> <<list>> <<ATTRIBUTE>> <<ANCHOR>>
<<vs>> <<259:8687-8689>> <<list>> <<ATTRIBUTE>> <<ANCHOR>>
<<learning_rate>> <<261:8813-8826>> <<int>> <<ATTRIBUTE>> <<ANCHOR>>
<<updates>> <<264:8993-9000>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<updates>> <<43:1280-1287>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<param>> <<45:1385-1390>> <<?>> <<VARIABLE>> <<ANCHOR>>
<<self>> <<47:1427-1431>> <<AdamOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<time_step>> <<47:1433-1442>> <<int>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<53:1609-1613>> <<AdamOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<msg>> <<53:1615-1618>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<verbose>> <<53:1620-1627>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<self>> <<142:4788-4792>> <<SGDOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<msg>> <<142:4794-4797>> <<str>> <<PARAMETER>> <<ANCHOR>>
<<verbose>> <<142:4799-4806>> <<bool>> <<PARAMETER>> <<ANCHOR>>
<<learning_rate>> <<145:4918-4931>> <<float>> <<ATTRIBUTE>> <<ANCHOR>>
<<self>> <<29:742-746>> <<BaseOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<params>> <<29:748-754>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<learning_rate_init>> <<29:756-774>> <<float>> <<PARAMETER>> <<ANCHOR>>
<<param>> <<30:815-820>> <<?>> <<SCOPE>> <<ANCHOR>>
<<params>> <<30:795-801>> <<list>> <<ATTRIBUTE>> <<ANCHOR>>
<<learning_rate_init>> <<31:846-864>> <<float>> <<ATTRIBUTE>> <<ANCHOR>>
<<learning_rate>> <<32:900-913>> <<float>> <<ATTRIBUTE>> <<ANCHOR>>
<<self>> <<128:4254-4258>> <<SGDOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<time_step>> <<128:4260-4269>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<learning_rate>> <<139:4642-4655>> <<{int||float}>> <<ATTRIBUTE>> <<ANCHOR>>
<<self>> <<159:5391-5395>> <<SGDOptimizer>> <<PARAMETER>> <<ANCHOR>>
<<grads>> <<159:5397-5402>> <<?>> <<PARAMETER>> <<ANCHOR>>
<<updates>> <<173:5864-5871>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<velocities>> <<175:6013-6023>> <<list>> <<ATTRIBUTE>> <<ANCHOR>>
<<updates>> <<178:6076-6083>> <<list>> <<VARIABLE>> <<ANCHOR>>
<<BaseOptimizer>> <<74:2092-2105>> <<type>> <<VARIABLE>> <<LINK>>
<<BaseOptimizer>> <<184:6266-6279>> <<type>> <<VARIABLE>> <<LINK>>
<<SGDOptimizer>> <<120:3959-3971>> <<type>> <<VARIABLE>> <<LINK>>
<<self>> <<120:3973-3977>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<params>> <<120:3988-3994>> <<list>> <<VARIABLE>> <<LINK>>
<<learning_rate_init>> <<120:3996-4014>> <<?>> <<VARIABLE>> <<LINK>>
<<lr_schedule>> <<122:4046-4057>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<122:4027-4031>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<momentum>> <<123:4083-4091>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<123:4067-4071>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<nesterov>> <<124:4117-4125>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<124:4101-4105>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<power_t>> <<125:4150-4157>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<125:4135-4139>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<params>> <<126:4220-4226>> <<list>> <<VARIABLE>> <<LINK>>
<<param>> <<126:4211-4216>> <<?>> <<VARIABLE>> <<LINK>>
<<param>> <<126:4200-4205>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<126:4167-4171>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<AdamOptimizer>> <<233:7749-7762>> <<type>> <<VARIABLE>> <<LINK>>
<<self>> <<233:7764-7768>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<params>> <<233:7779-7785>> <<list>> <<VARIABLE>> <<LINK>>
<<learning_rate_init>> <<233:7787-7805>> <<?>> <<VARIABLE>> <<LINK>>
<<beta_1>> <<235:7832-7838>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<235:7818-7822>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<beta_2>> <<236:7862-7868>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<236:7848-7852>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<epsilon>> <<237:7893-7900>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<237:7878-7882>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<238:7910-7914>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<params>> <<239:7975-7981>> <<list>> <<VARIABLE>> <<LINK>>
<<param>> <<239:7966-7971>> <<?>> <<VARIABLE>> <<LINK>>
<<param>> <<239:7955-7960>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<239:7930-7934>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<params>> <<240:8037-8043>> <<list>> <<VARIABLE>> <<LINK>>
<<param>> <<240:8028-8033>> <<?>> <<VARIABLE>> <<LINK>>
<<param>> <<240:8017-8022>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<240:7992-7996>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<43:1290-1294>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<_get_updates>> <<43:1295-1307>> <<{function||function}>> <<VARIABLE>> <<LINK>>
<<grads>> <<43:1308-1313>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<256:8542-8546>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<t>> <<256:8547-8548>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<258:8656-8660>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<ms>> <<258:8661-8663>> <<list>> <<VARIABLE>> <<LINK>>
<<grads>> <<258:8665-8670>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<257:8574-8578>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<beta_1>> <<257:8579-8585>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<257:8597-8601>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<beta_1>> <<257:8602-8608>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<257:8563-8567>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<ms>> <<257:8568-8570>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<260:8782-8786>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<vs>> <<260:8787-8789>> <<list>> <<VARIABLE>> <<LINK>>
<<grads>> <<260:8791-8796>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<259:8693-8697>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<beta_2>> <<259:8698-8704>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<259:8716-8720>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<beta_2>> <<259:8721-8727>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<259:8682-8686>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<vs>> <<259:8687-8689>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<261:8830-8834>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<262:8899-8903>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<beta_2>> <<262:8904-8910>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<262:8914-8918>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<t>> <<262:8919-8920>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<263:8960-8964>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<beta_1>> <<263:8965-8971>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<263:8975-8979>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<t>> <<263:8980-8981>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<261:8808-8812>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<265:9094-9098>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<ms>> <<265:9099-9101>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<265:9103-9107>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<vs>> <<265:9108-9110>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<264:9005-9009>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<learning_rate>> <<264:9010-9023>> <<int>> <<VARIABLE>> <<LINK>>
<<self>> <<264:9044-9048>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<epsilon>> <<264:9049-9056>> <<?>> <<VARIABLE>> <<LINK>>
<<updates>> <<266:9129-9136>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<44:1349-1353>> <<AdamOptimizer>> <<VARIABLE>> <<LINK>>
<<updates>> <<44:1362-1369>> <<list>> <<VARIABLE>> <<LINK>>
<<verbose>> <<69:1999-2006>> <<?>> <<VARIABLE>> <<LINK>>
<<msg>> <<70:2027-2030>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<143:4821-4825>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<lr_schedule>> <<143:4826-4837>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<144:4869-4873>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<145:4913-4917>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<verbose>> <<146:4958-4965>> <<bool>> <<VARIABLE>> <<LINK>>
<<msg>> <<147:4994-4997>> <<str>> <<VARIABLE>> <<LINK>>
<<self>> <<148:5060-5064>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<learning_rate>> <<148:5065-5078>> <<float>> <<VARIABLE>> <<LINK>>
<<verbose>> <<151:5149-5156>> <<bool>> <<VARIABLE>> <<LINK>>
<<msg>> <<152:5185-5188>> <<str>> <<VARIABLE>> <<LINK>>
<<verbose>> <<155:5290-5297>> <<bool>> <<VARIABLE>> <<LINK>>
<<msg>> <<156:5322-5325>> <<str>> <<VARIABLE>> <<LINK>>
<<params>> <<30:824-830>> <<?>> <<VARIABLE>> <<LINK>>
<<param>> <<30:815-820>> <<?>> <<VARIABLE>> <<LINK>>
<<param>> <<30:805-810>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<30:790-794>> <<BaseOptimizer>> <<VARIABLE>> <<LINK>>
<<learning_rate_init>> <<31:867-885>> <<float>> <<VARIABLE>> <<LINK>>
<<self>> <<31:841-845>> <<BaseOptimizer>> <<VARIABLE>> <<LINK>>
<<learning_rate_init>> <<32:922-940>> <<float>> <<VARIABLE>> <<LINK>>
<<self>> <<32:895-899>> <<BaseOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<138:4590-4594>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<139:4665-4669>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<time_step>> <<140:4728-4737>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<140:4746-4750>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<139:4637-4641>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<174:5974-5978>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<grads>> <<174:5991-5996>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<173:5875-5879>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<173:5902-5906>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<learning_rate>> <<173:5907-5920>> <<{int||float}>> <<VARIABLE>> <<LINK>>
<<updates>> <<175:6026-6033>> <<list>> <<VARIABLE>> <<LINK>>
<<self>> <<175:6008-6012>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<177:6048-6052>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<179:6190-6194>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<velocities>> <<179:6195-6205>> <<list>> <<VARIABLE>> <<LINK>>
<<grads>> <<179:6207-6212>> <<?>> <<VARIABLE>> <<LINK>>
<<self>> <<178:6087-6091>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<self>> <<178:6114-6118>> <<SGDOptimizer>> <<VARIABLE>> <<LINK>>
<<learning_rate>> <<178:6119-6132>> <<{int||float}>> <<VARIABLE>> <<LINK>>
<<updates>> <<181:6233-6240>> <<list>> <<VARIABLE>> <<LINK>>
<<learning_rate>> <<144:4874-4887>> <<{int||float}>> <<VARIABLE>> <<LINK>>
<<learning_rate>> <<145:4918-4931>> <<{int||float}>> <<VARIABLE>> <<LINK>>
